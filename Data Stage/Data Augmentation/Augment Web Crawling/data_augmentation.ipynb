{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import queue\n",
    "import re\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các hàm liên quan đến Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_list = [\n",
    "    \"API-KEY1\",\n",
    "    \"API-KEY2\",\n",
    "    \"API-KEY3\",\n",
    "    \"API-KEY4\",\n",
    "    \"API-KEY5\",\n",
    "]\n",
    "\n",
    "model_list = [\n",
    "    \"gemini-1.5-flash\",\n",
    "    \"gemini-1.5-flash-8b\",\n",
    "    \"gemini-1.0-pro\"\n",
    "]\n",
    "\n",
    "API_queue = queue.Queue()\n",
    "for model in model_list:\n",
    "    for api in API_list:\n",
    "        API_queue.put((model, api))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model with API\n",
    "def get_item():\n",
    "    model, api = API_queue.get()\n",
    "    API_queue.put((model, api))\n",
    "    return model, api\n",
    "\n",
    "# Config API function\n",
    "def config_API(API_KEY):\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    \n",
    "# Request function\n",
    "def request(API_KEY, model_name=\"gemini-1.0-pro\", prompt=None):\n",
    "    try:\n",
    "        if prompt is not None:\n",
    "            config_API(API_KEY)\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        else:\n",
    "            print(\"Prompt must be NOT None!\")\n",
    "            return None\n",
    "    except:\n",
    "        print(\"\\nSomething went wrong! Try again!\")\n",
    "        return None\n",
    "    \n",
    "# clear response function\n",
    "def clear_response(response):\n",
    "    # Thay thế \\n\\n bằng \\n\n",
    "    response = re.sub(r'\\n\\n+', '\\n', response)\n",
    "    \n",
    "    # Loại bỏ markdown như ** và *\n",
    "    response = re.sub(r'\\*\\*|\\*', '', response)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thiết kế Prompt - Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Hướng dẫn: Bạn có vai trò tăng cường dữ liệu hội thoại giữa bác sĩ và người dùng. Hãy tăng cường dữ liệu bằng cách tạo ra nhiều kịch bản liên quan với câu hỏi và cách trả lời đa dạng dựa trên hội thoại mẫu mà người dùng cung cấp.\n",
    "Lưu ý: Mỗi đoạn hội thoại đều được bắt đầu bằng [START] và kết thúc là [END] không cần markdown, trình bày càng dài càng đủ ý càng tốt.\n",
    "Hội thoại được cung cấp: {}\n",
    "Hãy tăng cường dữ liệu lên 5 lần\n",
    "{}\"\"\"\n",
    "\n",
    "example = \"\"\"Ví dụ bạn sẽ sinh ra giống như [START][{\"role\": \"Người dùng\", \"message\":...},{\"role\": \"Bác sĩ\", ...}][END] thêm 5 lần như vậy (Không được thêm ```json hay bất cứ thứ gì)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dữ liệu Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_crawling.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Một số hàm cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text in response [START]...[END]\n",
    "def extract_response(response):\n",
    "    # Sử dụng regex để tìm tất cả các chuỗi nằm giữa [START] và [END]\n",
    "    pattern = r'\\[START\\](.*?)\\[END\\]'\n",
    "    conversations = re.findall(pattern, response, re.DOTALL)  # re.DOTALL để match cả xuống dòng\n",
    "\n",
    "    # Loại bỏ các khoảng trắng thừa đầu và cuối chuỗi\n",
    "    conversations = [conv.strip() for conv in conversations]\n",
    "    \n",
    "    return conversations\n",
    "    \n",
    "# Save csv function\n",
    "def save_csv(data:dict, path:str):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"conversation\": []\n",
    "}\n",
    "\n",
    "def aug(conversation):\n",
    "    prompt = template.format(conversation,example)\n",
    "    while True:\n",
    "        model, api = get_item()\n",
    "        response = request(api, model, prompt)\n",
    "        if response is not None:\n",
    "            break\n",
    "        time.sleep(2)\n",
    "        \n",
    "    response = clear_response(response)\n",
    "    aug_conversations = extract_response(response)\n",
    "    for aug_conver in aug_conversations:\n",
    "        if aug_conver[0] != \"[\":\n",
    "            aug_conver = \"[\" + aug_conver\n",
    "        if aug_conver[-1] != \"]\":\n",
    "            aug_conver = aug_conver + \"]\"\n",
    "        data_dict[\"conversation\"].append(aug_conver)\n",
    "\n",
    "def data_augmentation():\n",
    "    batch = []\n",
    "    for conversation in tqdm(df[\"conversation\"].iloc[431:], desc=\"Data Augmentation\"):\n",
    "        batch.append(conversation)\n",
    "        if len(batch) >= 10:\n",
    "            for i in range(10):\n",
    "                with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "                    results = list(executor.map(aug, batch))\n",
    "                save_csv(data_dict, \"data_augmentation2.csv\")\n",
    "            batch = []\n",
    "    print(\"DONE!\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
